{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spark sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-create df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, max, sum, countDistinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- bigram: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      " |-- pages: integer (nullable = true)\n",
      " |-- books: integer (nullable = true)\n",
      "\n",
      "+--------+----+-----+-----+-----+\n",
      "|  bigram|year|count|pages|books|\n",
      "+--------+----+-----+-----+-----+\n",
      "|! $17.95|1985|    1|    1|    1|\n",
      "|! $17.95|1987|    1|    1|    1|\n",
      "|! $17.95|1990|    1|    1|    1|\n",
      "|! $17.95|1991|    1|    1|    1|\n",
      "|! $17.95|1992|    5|    5|    5|\n",
      "|! $17.95|1993|    2|    2|    2|\n",
      "|! $17.95|1995|    1|    1|    1|\n",
      "|! $17.95|1996|    4|    2|    2|\n",
      "|! $17.95|1997|    6|    5|    5|\n",
      "|! $17.95|1998|    4|    3|    3|\n",
      "+--------+----+-----+-----+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"lab3\").getOrCreate()\n",
    "\n",
    "df = spark.read.csv(\"ngram.csv\", header=False, inferSchema=True, sep='\\t')\n",
    "df = df.toDF('bigram','year','count', 'pages','books')\n",
    "\n",
    "df.printSchema()\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-tmp table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"ngram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1-return all bigrams where the Count is greater than five."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+-----+-----+-----+\n",
      "|  bigram|year|count|pages|books|\n",
      "+--------+----+-----+-----+-----+\n",
      "|! $17.95|1997|    6|    5|    5|\n",
      "|! $17.95|1999|   11|   10|   10|\n",
      "|! $17.95|2000|   11|    9|    9|\n",
      "|! $17.95|2004|   14|   14|   14|\n",
      "|! $17.95|2005|   13|   13|   13|\n",
      "|    ! 09|1899|    6|    6|    5|\n",
      "|    ! 09|1916|    7|    7|    4|\n",
      "|    ! 09|1936|    6|    6|    6|\n",
      "|    ! 09|1997|    6|    5|    5|\n",
      "|    ! 09|1999|   11|   10|   10|\n",
      "+--------+----+-----+-----+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sql\n",
    "spark.sql(\"Select * from ngram where count > 5\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+-----+-----+-----+\n",
      "|  bigram|year|count|pages|books|\n",
      "+--------+----+-----+-----+-----+\n",
      "|! $17.95|1997|    6|    5|    5|\n",
      "|! $17.95|1999|   11|   10|   10|\n",
      "|! $17.95|2000|   11|    9|    9|\n",
      "|! $17.95|2004|   14|   14|   14|\n",
      "|! $17.95|2005|   13|   13|   13|\n",
      "|    ! 09|1899|    6|    6|    5|\n",
      "|    ! 09|1916|    7|    7|    4|\n",
      "|    ! 09|1936|    6|    6|    6|\n",
      "|    ! 09|1997|    6|    5|    5|\n",
      "|    ! 09|1999|   11|   10|   10|\n",
      "+--------+----+-----+-----+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sparkSql\n",
    "df.filter(\"count > 5\").select(\"*\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+-----+-----+-----+\n",
      "|  bigram|year|count|pages|books|\n",
      "+--------+----+-----+-----+-----+\n",
      "|! $17.95|1997|    6|    5|    5|\n",
      "|! $17.95|1999|   11|   10|   10|\n",
      "|! $17.95|2000|   11|    9|    9|\n",
      "|! $17.95|2004|   14|   14|   14|\n",
      "|! $17.95|2005|   13|   13|   13|\n",
      "|    ! 09|1899|    6|    6|    5|\n",
      "|    ! 09|1916|    7|    7|    4|\n",
      "|    ! 09|1936|    6|    6|    6|\n",
      "|    ! 09|1997|    6|    5|    5|\n",
      "|    ! 09|1999|   11|   10|   10|\n",
      "+--------+----+-----+-----+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df['count'] > 5).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+-----+-----+-----+\n",
      "|  bigram|year|count|pages|books|\n",
      "+--------+----+-----+-----+-----+\n",
      "|! $17.95|1997|    6|    5|    5|\n",
      "|! $17.95|1999|   11|   10|   10|\n",
      "|! $17.95|2000|   11|    9|    9|\n",
      "|! $17.95|2004|   14|   14|   14|\n",
      "|! $17.95|2005|   13|   13|   13|\n",
      "|    ! 09|1899|    6|    6|    5|\n",
      "|    ! 09|1916|    7|    7|    4|\n",
      "|    ! 09|1936|    6|    6|    6|\n",
      "|    ! 09|1997|    6|    5|    5|\n",
      "|    ! 09|1999|   11|   10|   10|\n",
      "+--------+----+-----+-----+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(col('count') > 5).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2-return the total number of bigrams for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+\n",
      "|year|total_bigram|\n",
      "+----+------------+\n",
      "|1829|           1|\n",
      "|1990|           2|\n",
      "|1903|           1|\n",
      "|1884|           1|\n",
      "|1888|           1|\n",
      "|1924|           1|\n",
      "|2003|           2|\n",
      "|1823|           1|\n",
      "|2007|           2|\n",
      "|1869|           1|\n",
      "+----+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sql\n",
    "spark.sql('select year, count(*) as total_bigram from ngram group by year').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+\n",
      "|year|total_bigram|\n",
      "+----+------------+\n",
      "|1829|           1|\n",
      "|1990|           2|\n",
      "|1903|           1|\n",
      "|1884|           1|\n",
      "|1888|           1|\n",
      "|1924|           1|\n",
      "|2003|           2|\n",
      "|1823|           1|\n",
      "|2007|           2|\n",
      "|1869|           1|\n",
      "+----+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sparkSql\n",
    "df.groupBy('year').agg(count('*').alias('total_bigram')).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3-return the bigrams with the highest Count for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+---------+\n",
      "|year|  bigram|max_count|\n",
      "+----+--------+---------+\n",
      "|2002|    ! 09|        5|\n",
      "|1932|    ! 09|        1|\n",
      "|1880|    ! 09|        2|\n",
      "|1935|    ! 09|        2|\n",
      "|1999|    ! 09|       11|\n",
      "|1829|    ! 09|        3|\n",
      "|1999|! $17.95|       11|\n",
      "|1887|    ! 09|        1|\n",
      "|2007|    ! 09|        2|\n",
      "|1899|    ! 09|        6|\n",
      "+----+--------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sql\n",
    "spark.sql('select year, bigram, MAX(count) as max_count from ngram group by year, bigram').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+----------+\n",
      "|year|  bigram|max(count)|\n",
      "+----+--------+----------+\n",
      "|2002|    ! 09|         5|\n",
      "|1932|    ! 09|         1|\n",
      "|1880|    ! 09|         2|\n",
      "|1935|    ! 09|         2|\n",
      "|1999|    ! 09|        11|\n",
      "|1829|    ! 09|         3|\n",
      "|1999|! $17.95|        11|\n",
      "|1887|    ! 09|         1|\n",
      "|2007|    ! 09|         2|\n",
      "|1899|    ! 09|         6|\n",
      "+----+--------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sparkSql\n",
    "df.groupBy(\"year\",\"bigram\").max(\"count\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4-return all bigrams that appeared in 20 different years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|  bigram|\n",
      "+--------+\n",
      "|! $17.95|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sql\n",
    "spark.sql('select bigram from ngram group by bigram having count(distinct year) = 20').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+\n",
      "|  bigram|distinct_year|\n",
      "+--------+-------------+\n",
      "|! $17.95|           20|\n",
      "+--------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sparkSql\n",
    "df.groupby('bigram').agg(countDistinct('year').alias('distinct_year')).filter('distinct_year = 20').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5-return all bigrams that contain the character '!' in the first part and the character '9' in the second part (the two parts are separated by a space)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "|year|  bigram|\n",
      "+----+--------+\n",
      "|1985|! $17.95|\n",
      "|1987|! $17.95|\n",
      "|1990|! $17.95|\n",
      "|1991|! $17.95|\n",
      "|1992|! $17.95|\n",
      "|1993|! $17.95|\n",
      "|1995|! $17.95|\n",
      "|1996|! $17.95|\n",
      "|1997|! $17.95|\n",
      "|1998|! $17.95|\n",
      "+----+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sql\n",
    "spark.sql('select year, bigram from ngram where bigram like \"%!% %9%\"').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "|year|  bigram|\n",
      "+----+--------+\n",
      "|1985|! $17.95|\n",
      "|1987|! $17.95|\n",
      "|1990|! $17.95|\n",
      "|1991|! $17.95|\n",
      "|1992|! $17.95|\n",
      "|1993|! $17.95|\n",
      "|1995|! $17.95|\n",
      "|1996|! $17.95|\n",
      "|1997|! $17.95|\n",
      "|1998|! $17.95|\n",
      "+----+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sparkSql\n",
    "df.filter('bigram like \"%%! %9%\"').select('year', 'bigram').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.6-return the bigrams that appeared in all the years present in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|bigram|\n",
      "+------+\n",
      "|  ! 09|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sql\n",
    "spark.sql('select bigram from ngram group by bigram having count(distinct year) = (select count(distinct year) from ngram)').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(count(DISTINCT year)=100)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(countDistinct('year')).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n",
      "|bigram|distinct_year|\n",
      "+------+-------------+\n",
      "|  ! 09|          100|\n",
      "+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sparkSql\n",
    "df.groupby('bigram').agg(countDistinct('year').alias('distinct_year')).filter(col('distinct_year') == df.select(countDistinct('year')).collect()[0][0]).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.7-return the total number of pages and books in which each bigram appeared for each available year, sorted in alphabetical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+-----------+-----------+\n",
      "|year|  bigram|total_pages|total_books|\n",
      "+----+--------+-----------+-----------+\n",
      "|2002|! $17.95|          5|          5|\n",
      "|1993|! $17.95|          2|          2|\n",
      "|2006|! $17.95|          5|          5|\n",
      "|1985|! $17.95|          1|          1|\n",
      "|1996|! $17.95|          2|          2|\n",
      "|1999|! $17.95|         10|         10|\n",
      "|1995|! $17.95|          1|          1|\n",
      "|2007|! $17.95|          2|          2|\n",
      "|1991|! $17.95|          1|          1|\n",
      "|2000|! $17.95|          9|          9|\n",
      "+----+--------+-----------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sql\n",
    "spark.sql('select year, bigram, sum(pages) as total_pages, sum(books) as total_books from ngram group by year, bigram order by bigram').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+-----------+-----------+\n",
      "|year|  bigram|total_pages|total_books|\n",
      "+----+--------+-----------+-----------+\n",
      "|2002|! $17.95|          5|          5|\n",
      "|1993|! $17.95|          2|          2|\n",
      "|2006|! $17.95|          5|          5|\n",
      "|1985|! $17.95|          1|          1|\n",
      "|1996|! $17.95|          2|          2|\n",
      "|1999|! $17.95|         10|         10|\n",
      "|1995|! $17.95|          1|          1|\n",
      "|2007|! $17.95|          2|          2|\n",
      "|1991|! $17.95|          1|          1|\n",
      "|2000|! $17.95|          9|          9|\n",
      "+----+--------+-----------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sparkSql\n",
    "df.groupby('year', 'bigram').agg(sum('pages').alias('total_pages'), sum('books').alias('total_books')).orderBy('bigram').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.8-return the total number of distinct bigrams for each year, sorted in descending order of the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------+\n",
      "|year|distinct_bigram|\n",
      "+----+---------------+\n",
      "|2008|              2|\n",
      "|2007|              2|\n",
      "|2006|              2|\n",
      "|2005|              2|\n",
      "|2004|              2|\n",
      "|2003|              2|\n",
      "|2002|              2|\n",
      "|2001|              2|\n",
      "|2000|              2|\n",
      "|1999|              2|\n",
      "+----+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sql\n",
    "spark.sql('select year, count(distinct bigram) as distinct_bigram from ngram group by year order by year desc').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------+\n",
      "|year|distinct_bigram|\n",
      "+----+---------------+\n",
      "|2008|              2|\n",
      "|2007|              2|\n",
      "|2006|              2|\n",
      "|2005|              2|\n",
      "|2004|              2|\n",
      "|2003|              2|\n",
      "|2002|              2|\n",
      "|2001|              2|\n",
      "|2000|              2|\n",
      "|1999|              2|\n",
      "+----+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('year').agg(countDistinct('bigram').alias('distinct_bigram')).orderBy('year', ascending=False).show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
